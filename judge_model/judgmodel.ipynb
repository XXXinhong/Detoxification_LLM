{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b637794-79fa-422f-b085-9136b9f23ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fa4591-acea-445f-ae4c-b6be8f87f79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('dirty.csv')\n",
    "clean = pd.read_csv('clean.csv')\n",
    "\n",
    "toxic['tag'] = 1\n",
    "clean['tag'] = 0\n",
    "toxic = toxic.drop(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1)\n",
    "clean = clean.drop(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65b33daf-e461-4398-b866-d316f8bfd5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.concat([clean, toxic], ignore_index=True).sample(frac=1, random_state=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78b4651-7dfb-42d0-b40d-82f503a3797f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment_text  tag\n",
      "0       Yes I read the explanations. And what you say ...    0\n",
      "1       Image:Aerotow_launch_MGC.jpg listed for deleti...    0\n",
      "2       okay its fine. the image wasn't downloaded at ...    0\n",
      "3       Just now writing here but I like Austin said, ...    0\n",
      "4       Deletion review for Tyler Clementi==\\nAn edito...    0\n",
      "...                                                   ...  ...\n",
      "154246  GA reassessment of Multiple sequence alignment...    0\n",
      "154247  2014 (UTC)\\n\\nToday, many people from countrie...    0\n",
      "154248  What's that 12.205.247.27 deletion? \\n\\nI see ...    0\n",
      "154249  Yes, I must second this.  Scottsdale is not at...    0\n",
      "154250  How was the external link inappropriate? Why d...    0\n",
      "\n",
      "[154251 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ca56bd-b793-4ea8-bed4-4a20e57d3cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data[0:int(len(data)*0.95)]\n",
    "test = data[int(len(data)*0.95):-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea02539-0282-4489-b5c6-c96c6ceefca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "#re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): \n",
    "    re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a5baad-cf98-41d2-a655-01c5bcc7a697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:594: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(train['comment_text'])\n",
    "test_term_doc = vec.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b5221a-f9a7-4ce3-b3c7-7162de02b390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9addd1-2ec9-4dd3-b188-45de189035f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887feac8-42c8-4db0-bcee-00ce5c8be3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=False)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9693bb2b-0cfe-4ade-8168-aa3542ada253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit tag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "label_cols = ['tag']\n",
    "\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "array = []\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    array.append([m,r])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2af7a35c-64ab-42bc-9b4d-8c592c4c043c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(m, file)\n",
    "with open('r_values.pkl', 'wb') as file:\n",
    "    pickle.dump(r, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37a90d57-a562-4b56-b0b0-b8f9d1e4d430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca27114e-40aa-4875-82d8-574413fae264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Judge():\n",
    "    def __init__(self):\n",
    "        with open('judge_model/tfidf_vectorizer.pkl', 'rb') as file:\n",
    "            vec = pickle.load(file)\n",
    "        with open('judge_model/logistic_regression_model.pkl', 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        with open('judge_model/r_values.pkl', 'rb') as file:\n",
    "            r = pickle.load(file)\n",
    "            \n",
    "    def judge(self, words):\n",
    "        tokens = vec.transform([words])\n",
    "        preds = m.predict_proba(tokens.multiply(r))[:,1]\n",
    "        \n",
    "        return 1 if preds>0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b3d1d74-ebbf-4278-b27d-7cd3e63134b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Judge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4e9e390-8e7b-4144-ba2f-1d9d878160bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(test.judge(\"fuck you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83406b-20c2-469e-8b5c-4a46a84e943b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
